{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOD7pBaSeAaL3Y5cEoPFSde",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Propa-Punam/Wifi-RSS-Crowdsensing/blob/main/correct%20so%20far/without_grey_code_correct_so_far.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ufhx5AXSP_U",
        "outputId": "a0455943-548b-4bac-cb76-89d40f35cc86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded:\n",
            "Training samples: 25\n",
            "Test samples: 23\n",
            "Unique rooms in training: ['203' '204' 'l1' 'l2' 'l3']\n",
            "Unique rooms in test: ['203' '204']\n",
            "\n",
            "Initializing centroids for zones:\n",
            "Zone 203 (encoded: 0)\n",
            "Zone 204 (encoded: 1)\n",
            "Zone l1 (encoded: 2)\n",
            "Zone l2 (encoded: 3)\n",
            "Zone l3 (encoded: 4)\n",
            "Zone 203 centroid initialized with 12 samples\n",
            "Zone 204 centroid initialized with 10 samples\n",
            "Zone l1 centroid initialized with 1 samples\n",
            "Zone l2 centroid initialized with 1 samples\n",
            "Zone l3 centroid initialized with 1 samples\n",
            "\n",
            "Starting training...\n",
            "Epoch 10/100, Training Accuracy: 40.00%\n",
            "Epoch 20/100, Training Accuracy: 16.00%\n",
            "Epoch 30/100, Training Accuracy: 36.00%\n",
            "Epoch 40/100, Training Accuracy: 40.00%\n",
            "Epoch 50/100, Training Accuracy: 48.00%\n",
            "Epoch 60/100, Training Accuracy: 48.00%\n",
            "Epoch 70/100, Training Accuracy: 48.00%\n",
            "Epoch 80/100, Training Accuracy: 48.00%\n",
            "Epoch 90/100, Training Accuracy: 48.00%\n",
            "Epoch 100/100, Training Accuracy: 48.00%\n",
            "\n",
            "Test Accuracy: 52.17%\n",
            "\n",
            "Prediction Summary:\n",
            "  Room  Total Cases  Correct Predictions  Accuracy\n",
            "0  203           12                   12     100.0\n",
            "1  204           11                    0       0.0\n",
            "\n",
            "Detailed results have been saved to 'prediction_results.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "class SimplifiedCPNWifiLocalizer:\n",
        "    def __init__(self, learning_rate=0.1):\n",
        "        self.beta = learning_rate\n",
        "        self.kohonen_weights = None\n",
        "        self.zones = None\n",
        "        self.n_features = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def _initialize_centroids(self, X, y_encoded, original_labels):\n",
        "        \"\"\"Initialize centroids using mean RSSI vector for each zone\"\"\"\n",
        "        unique_zones = np.unique(y_encoded)\n",
        "        self.zones = unique_zones\n",
        "        self.n_features = X.shape[1]\n",
        "\n",
        "        print(\"Initializing centroids for zones:\")\n",
        "        for i, zone in enumerate(unique_zones):\n",
        "            original_zone = original_labels[y_encoded == zone][0]\n",
        "            print(f\"Zone {original_zone} (encoded: {zone})\")\n",
        "\n",
        "        # Initialize Kohonen layer weights with zone means\n",
        "        self.kohonen_weights = np.zeros((len(unique_zones), self.n_features))\n",
        "        for i, zone in enumerate(unique_zones):\n",
        "            zone_samples = X[y_encoded == zone]\n",
        "            self.kohonen_weights[i] = np.mean(zone_samples, axis=0)\n",
        "            original_zone = original_labels[y_encoded == zone][0]\n",
        "            print(f\"Zone {original_zone} centroid initialized with {len(zone_samples)} samples\")\n",
        "\n",
        "    def _compute_activation(self, rss_vector):\n",
        "        \"\"\"Compute activation values for each zone neuron\"\"\"\n",
        "        return np.sum(rss_vector * self.kohonen_weights, axis=1)\n",
        "\n",
        "    def train(self, X, y, epochs=100):\n",
        "        \"\"\"Train the CPN model using only Kohonen layer\"\"\"\n",
        "        # Convert string labels to numeric\n",
        "        original_labels = y.copy()\n",
        "        y_encoded = self.label_encoder.fit_transform(y)\n",
        "\n",
        "        # Initialize centroids\n",
        "        self._initialize_centroids(X, y_encoded, original_labels)\n",
        "\n",
        "        print(\"\\nStarting training...\")\n",
        "        for epoch in range(epochs):\n",
        "            epoch_accuracy = 0\n",
        "            for i in range(len(X)):\n",
        "                # Get current sample\n",
        "                rss_vector = X[i]\n",
        "                true_zone = y_encoded[i]\n",
        "\n",
        "                # Compute activation values\n",
        "                activation_values = self._compute_activation(rss_vector)\n",
        "\n",
        "                # Find winning neuron\n",
        "                winner_idx = np.argmax(activation_values)\n",
        "\n",
        "                # Update Kohonen weights for winning neuron\n",
        "                self.kohonen_weights[winner_idx] += self.beta * (\n",
        "                    rss_vector - self.kohonen_weights[winner_idx]\n",
        "                )\n",
        "\n",
        "                # Track accuracy during training\n",
        "                true_zone_idx = np.where(self.zones == true_zone)[0][0]\n",
        "                if winner_idx == true_zone_idx:\n",
        "                    epoch_accuracy += 1\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f\"Epoch {epoch + 1}/{epochs}, Training Accuracy: {epoch_accuracy/len(X)*100:.2f}%\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict zones for new RSSI measurements\"\"\"\n",
        "        predictions = []\n",
        "        for rss_vector in X:\n",
        "            # Compute activation values\n",
        "            activation_values = self._compute_activation(rss_vector)\n",
        "\n",
        "            # Find winning neuron directly maps to zone\n",
        "            winner_idx = np.argmax(activation_values)\n",
        "            predicted_zone = self.zones[winner_idx]\n",
        "            predictions.append(predicted_zone)\n",
        "\n",
        "        # Convert numeric predictions back to original labels\n",
        "        return self.label_encoder.inverse_transform(predictions)\n",
        "\n",
        "def prepare_data(df):\n",
        "    \"\"\"Prepare data by separating features and labels\"\"\"\n",
        "    X = df.iloc[:, 2:].values.astype(float)  # Convert RSSI values to float\n",
        "    y = df['room'].astype(str).values  # Ensure room numbers are strings\n",
        "    return X, y\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    train_df = pd.read_csv('/content/train.csv')\n",
        "    test_df = pd.read_csv('/content/test.csv')\n",
        "\n",
        "    # Convert room columns to string type\n",
        "    train_df['room'] = train_df['room'].astype(str)\n",
        "    test_df['room'] = test_df['room'].astype(str)\n",
        "\n",
        "    print(\"Data loaded:\")\n",
        "    print(f\"Training samples: {len(train_df)}\")\n",
        "    print(f\"Test samples: {len(test_df)}\")\n",
        "    print(f\"Unique rooms in training: {train_df['room'].unique()}\")\n",
        "    print(f\"Unique rooms in test: {test_df['room'].unique()}\\n\")\n",
        "\n",
        "    # Prepare training and test data\n",
        "    X_train, y_train = prepare_data(train_df)\n",
        "    X_test, y_test = prepare_data(test_df)\n",
        "\n",
        "    # Initialize and train the model\n",
        "    model = SimplifiedCPNWifiLocalizer(learning_rate=0.1)\n",
        "    model.train(X_train, y_train, epochs=100)\n",
        "\n",
        "    # Make predictions on test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and display results\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Create results DataFrame\n",
        "    results_df = pd.DataFrame({\n",
        "        'StudentID': test_df['StudentID'],\n",
        "        'Actual Room': y_test,\n",
        "        'Predicted Room': y_pred,\n",
        "        'Correct?': y_test == y_pred\n",
        "    })\n",
        "\n",
        "    # Print prediction summary\n",
        "    print(\"\\nPrediction Summary:\")\n",
        "    unique_rooms = sorted(set(np.concatenate([y_test, y_pred])))\n",
        "    room_summary = pd.DataFrame({\n",
        "        'Room': unique_rooms,\n",
        "        'Total Cases': [sum(y_test == room) for room in unique_rooms],\n",
        "        'Correct Predictions': [sum((y_test == room) & (y_pred == room)) for room in unique_rooms]\n",
        "    })\n",
        "    room_summary['Accuracy'] = (room_summary['Correct Predictions'] / room_summary['Total Cases'] * 100).round(2)\n",
        "    print(room_summary)\n",
        "\n",
        "    # Save results\n",
        "    results_df.to_csv('prediction_results.csv', index=False)\n",
        "    print(\"\\nDetailed results have been saved to 'prediction_results.csv'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}