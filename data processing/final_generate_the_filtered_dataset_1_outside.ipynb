{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJvih7Fl1wtpeTSPkQJ4N5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Propa-Punam/Wifi-RSS-Crowdsensing/blob/main/data%20processing/final_generate_the_filtered_dataset_1_outside.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWjNOUfHCuXQ",
        "outputId": "4e165ab4-a668-464f-e24e-cdff33b98657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Filtered data has been saved to /content/drive/My Drive/filtered_wifi_data_outside.csv\n",
            "Total records in filtered data: 286\n",
            "\n",
            "Unique MAC addresses have been saved to /content/drive/My Drive/unique_mac_addresses_outside.csv\n",
            "Total unique MAC-SSID pairs: 11\n",
            "\n",
            "Strengths per scan group have been saved to /content/drive/My Drive/strength_outside.csv\n",
            "Total records in strengths data: 39\n",
            "\n",
            "First few rows of filtered data:\n",
            "   entryId  StudentID  scanGroupIndex         MacAddress          SSID  \\\n",
            "0        1    1905008               0  60:63:4c:31:37:40       CSE-303   \n",
            "1        1    1905008               0  bc:22:28:21:09:24       CSE-205   \n",
            "2        1    1905008               0  18:0f:76:c3:06:8d       CSE-304   \n",
            "3        1    1905008               0  bc:22:28:21:09:ba       CSE-206   \n",
            "4        1    1905008               0  30:b5:c2:ea:5b:44  DataLab@BUET   \n",
            "\n",
            "   Strength  \n",
            "0       -54  \n",
            "1       -55  \n",
            "2       -56  \n",
            "3       -60  \n",
            "4       -61  \n",
            "\n",
            "First few rows of unique MAC addresses:\n",
            "           MacAddress     SSID\n",
            "7   bc:22:28:21:55:6b  CSE-104\n",
            "10  bc:22:28:21:55:6e  CSE-104\n",
            "4   00:22:b0:05:f3:bc  CSE-204\n",
            "5   bc:22:28:21:09:24  CSE-205\n",
            "8   bc:22:28:21:09:21  CSE-205\n",
            "\n",
            "First few rows of strengths per scan group:\n",
            "   entryId  StudentID         MacAddress     SSID  Strength_scan_0  \\\n",
            "0        1    1905008  bc:22:28:21:55:6e  CSE-104            -65.0   \n",
            "1        1    1905008  bc:22:28:21:55:6b  CSE-104           -100.0   \n",
            "2        1    1905008  00:22:b0:05:f3:bc  CSE-204            -62.0   \n",
            "3        1    1905008  bc:22:28:21:09:24  CSE-205            -55.0   \n",
            "4        1    1905008  bc:22:28:21:09:21  CSE-205           -100.0   \n",
            "\n",
            "   Strength_scan_1  Strength_scan_2  Strength_scan_3  Strength_scan_4  \\\n",
            "0            -65.0            -65.0              NaN            -64.0   \n",
            "1           -100.0           -100.0           -100.0           -100.0   \n",
            "2            -66.0            -52.0            -52.0            -48.0   \n",
            "3            -55.0            -55.0            -55.0            -57.0   \n",
            "4           -100.0           -100.0           -100.0           -100.0   \n",
            "\n",
            "   Strength_scan_5  ...  Strength_scan_11  Strength_scan_12  Strength_scan_13  \\\n",
            "0            -64.0  ...             -63.0             -63.0             -66.0   \n",
            "1           -100.0  ...            -100.0            -100.0            -100.0   \n",
            "2            -48.0  ...             -52.0               NaN             -45.0   \n",
            "3            -57.0  ...             -59.0               NaN             -62.0   \n",
            "4           -100.0  ...            -100.0            -100.0            -100.0   \n",
            "\n",
            "   Strength_scan_14  Strength_scan_15  Strength_scan_16  Strength_scan_17  \\\n",
            "0             -66.0             -66.0             -66.0             -70.0   \n",
            "1            -100.0            -100.0            -100.0            -100.0   \n",
            "2             -45.0             -45.0             -45.0             -54.0   \n",
            "3             -62.0             -62.0             -62.0             -62.0   \n",
            "4            -100.0            -100.0            -100.0            -100.0   \n",
            "\n",
            "   Strength_scan_18  Strength_scan_19  Strength_Count  \n",
            "0             -70.0             -70.0              19  \n",
            "1            -100.0            -100.0              20  \n",
            "2             -54.0             -57.0              19  \n",
            "3             -62.0             -60.0              19  \n",
            "4            -100.0            -100.0              20  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths for input and output files in Google Drive\n",
        "input_path_entries = '/content/drive/My Drive/entries.csv'\n",
        "input_path_scans = '/content/drive/My Drive/scan_lists.csv'\n",
        "output_path_filtered = '/content/drive/My Drive/filtered_wifi_data_outside.csv'\n",
        "output_path_unique_macs = '/content/drive/My Drive/unique_mac_addresses_outside.csv'\n",
        "output_path_strengths = '/content/drive/My Drive/strength_outside.csv'\n",
        "\n",
        "# Read the CSV files\n",
        "entries_df = pd.read_csv(input_path_entries)\n",
        "scans_df = pd.read_csv(input_path_scans)\n",
        "\n",
        "# List of SSIDs to filter\n",
        "target_ssids = [\n",
        "    \"CSE-206\", \"CSE-104\", \"CSE-202\", \"CSE-205\",\n",
        "    \"CSE-304\", \"CSE-204\", \"CSE-303\", \"DataLab@BUET\",\n",
        "    \"CSE-214\", \"CSE-G04\", \"CSE-401\", \"CSE-306\"\n",
        "]\n",
        "\n",
        "# Provided list of unique MAC addresses and SSIDs\n",
        "unique_mac_ssid_list = [\n",
        "    {\"MacAddress\": \"bc:22:28:21:55:6e\", \"SSID\": \"CSE-104\"},\n",
        "    {\"MacAddress\": \"bc:22:28:21:55:6b\", \"SSID\": \"CSE-104\"},\n",
        "    {\"MacAddress\": \"00:22:b0:05:f3:bc\", \"SSID\": \"CSE-204\"},\n",
        "    {\"MacAddress\": \"bc:22:28:21:09:24\", \"SSID\": \"CSE-205\"},\n",
        "    {\"MacAddress\": \"bc:22:28:21:09:21\", \"SSID\": \"CSE-205\"},\n",
        "    {\"MacAddress\": \"bc:22:28:21:09:ba\", \"SSID\": \"CSE-206\"},\n",
        "    {\"MacAddress\": \"bc:22:28:21:70:62\", \"SSID\": \"CSE-214\"},\n",
        "    {\"MacAddress\": \"60:63:4c:31:37:40\", \"SSID\": \"CSE-303\"},\n",
        "    {\"MacAddress\": \"18:0f:76:c3:06:8d\", \"SSID\": \"CSE-304\"},\n",
        "    {\"MacAddress\": \"60:63:4c:31:37:60\", \"SSID\": \"CSE-306\"},\n",
        "    {\"MacAddress\": \"00:1e:2a:ba:c8:20\", \"SSID\": \"CSE-401\"},\n",
        "    {\"MacAddress\": \"10:62:eb:77:b7:42\", \"SSID\": \"CSE-G04\"},\n",
        "    {\"MacAddress\": \"30:b5:c2:ea:5b:44\", \"SSID\": \"DataLab@BUET\"}\n",
        "]\n",
        "\n",
        "# Create lists to store the filtered data and unique MAC addresses\n",
        "filtered_data = []\n",
        "mac_ssid_pairs = set()  # Using a set to store unique MAC-SSID pairs\n",
        "\n",
        "# Iterate through each entry in entries.csv\n",
        "for _, entry_row in entries_df.iterrows():\n",
        "    entry_id = entry_row['entryId']\n",
        "    student_id = entry_row['StudentID']\n",
        "\n",
        "    # Get all scans for this entry_id\n",
        "    entry_scans = scans_df[scans_df['entryId'] == entry_id]\n",
        "\n",
        "    # Iterate through each scan group (0 to 19)\n",
        "    for scan_group in range(20):\n",
        "        group_scans = entry_scans[entry_scans['scanGroupIndex'] == scan_group]\n",
        "\n",
        "        # Filter for target SSIDs\n",
        "        for _, scan_row in group_scans.iterrows():\n",
        "            ssid = scan_row['SSID']\n",
        "            if ssid in target_ssids:\n",
        "                # Add to filtered data (for first output)\n",
        "                filtered_data.append({\n",
        "                    'entryId': entry_id,\n",
        "                    'StudentID': student_id,\n",
        "                    'scanGroupIndex': scan_group,\n",
        "                    'MacAddress': scan_row['MacAddress'],\n",
        "                    'SSID': ssid,\n",
        "                    'Strength': scan_row['Strength']\n",
        "                })\n",
        "\n",
        "                # Add to unique MAC-SSID pairs\n",
        "                mac_ssid_pairs.add((scan_row['MacAddress'], ssid))\n",
        "\n",
        "# Convert filtered data to DataFrame (first output)\n",
        "output_df_filtered = pd.DataFrame(filtered_data)\n",
        "output_df_filtered = output_df_filtered.sort_values(['entryId', 'scanGroupIndex'])\n",
        "\n",
        "# Convert unique MAC-SSID pairs to DataFrame (second output)\n",
        "unique_macs_data = [{'MacAddress': mac, 'SSID': ssid} for mac, ssid in mac_ssid_pairs]\n",
        "output_df_unique_macs = pd.DataFrame(unique_macs_data)\n",
        "output_df_unique_macs = output_df_unique_macs.sort_values('SSID')\n",
        "\n",
        "# Create a DataFrame for all possible combinations of entryId, StudentID, MacAddress, and SSID\n",
        "# First, get all unique entryId and StudentID pairs\n",
        "entry_student_pairs = entries_df[['entryId', 'StudentID']].drop_duplicates()\n",
        "\n",
        "# Create a DataFrame from the unique MAC-SSID list\n",
        "mac_ssid_df = pd.DataFrame(unique_mac_ssid_list)\n",
        "\n",
        "# Create a Cartesian product of entryId-StudentID pairs with MacAddress-SSID pairs\n",
        "all_combinations = (\n",
        "    entry_student_pairs.assign(key=1)\n",
        "    .merge(mac_ssid_df.assign(key=1), on='key')\n",
        "    .drop('key', axis=1)\n",
        ")\n",
        "\n",
        "# Pivot the filtered data to have a column for each scanGroupIndex's strength\n",
        "pivot_df = output_df_filtered.pivot_table(\n",
        "    index=['entryId', 'StudentID', 'MacAddress', 'SSID'],\n",
        "    columns='scanGroupIndex',\n",
        "    values='Strength',\n",
        "    aggfunc='first'  # Take the first value if there are duplicates\n",
        ")\n",
        "\n",
        "# Reset index to make entryId, StudentID, MacAddress, and SSID regular columns\n",
        "pivot_df = pivot_df.reset_index()\n",
        "\n",
        "# Rename the columns to indicate they are strengths for each scan group\n",
        "pivot_df.columns = ['entryId', 'StudentID', 'MacAddress', 'SSID'] + [f'Strength_scan_{i}' for i in range(20)]\n",
        "\n",
        "# Merge with all_combinations to ensure all MAC addresses are present for each entryId\n",
        "final_df = all_combinations.merge(pivot_df, on=['entryId', 'StudentID', 'MacAddress', 'SSID'], how='left')\n",
        "\n",
        "# Identify rows where all strength values are NaN\n",
        "strength_columns = [f'Strength_scan_{i}' for i in range(20)]\n",
        "all_nan_mask = final_df[strength_columns].isna().all(axis=1)\n",
        "\n",
        "# Assign -100 to all strength columns only for rows where all strengths are NaN\n",
        "final_df.loc[all_nan_mask, strength_columns] = -100\n",
        "\n",
        "# Add a column for the count of recorded strengths (excluding -100)\n",
        "final_df['Strength_Count'] = final_df[strength_columns].apply(\n",
        "    lambda row: sum(1 for val in row if pd.notna(val) and val != -100), axis=1\n",
        ")\n",
        "\n",
        "# Set Strength_Count to 20 for rows where all strengths are -100 (i.e., originally all NaN)\n",
        "final_df.loc[all_nan_mask, 'Strength_Count'] = 20\n",
        "\n",
        "# Save all DataFrames to CSV files in Google Drive\n",
        "output_df_filtered.to_csv(output_path_filtered, index=False)\n",
        "output_df_unique_macs.to_csv(output_path_unique_macs, index=False)\n",
        "final_df.to_csv(output_path_strengths, index=False)\n",
        "\n",
        "# Print summary information\n",
        "print(f\"Filtered data has been saved to {output_path_filtered}\")\n",
        "print(f\"Total records in filtered data: {len(output_df_filtered)}\")\n",
        "print(f\"\\nUnique MAC addresses have been saved to {output_path_unique_macs}\")\n",
        "print(f\"Total unique MAC-SSID pairs: {len(output_df_unique_macs)}\")\n",
        "print(f\"\\nStrengths per scan group have been saved to {output_path_strengths}\")\n",
        "print(f\"Total records in strengths data: {len(final_df)}\")\n",
        "\n",
        "# Display the first few rows of all outputs\n",
        "print(\"\\nFirst few rows of filtered data:\")\n",
        "print(output_df_filtered.head())\n",
        "print(\"\\nFirst few rows of unique MAC addresses:\")\n",
        "print(output_df_unique_macs.head())\n",
        "print(\"\\nFirst few rows of strengths per scan group:\")\n",
        "print(final_df.head())"
      ]
    }
  ]
}